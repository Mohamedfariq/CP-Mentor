{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0797167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/6pycpdf50h17xp8s7qg7y93m0000gn/T/ipykernel_26359/2502829658.py:11: DtypeWarning: Columns (0: openId) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(HANDLES_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique handles available: 898802\n",
      "âœ… Saved: cf_dataset_ml/users_3k.csv | Count: 3000\n",
      "Example handles: ['Ravinder2000', 'sivapavan1998', 'noelkawn', 'hoangle10tin', 'R_K_RATHORE', 'manhvinh', 'dhruvsavani008', '_ud', 'Vibhum', 'Sarfarozkhuja']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Create output folder\n",
    "os.makedirs(\"cf_dataset_ml\", exist_ok=True)\n",
    "\n",
    "# 2) Load your 90k handles file\n",
    "HANDLES_PATH = \"/Users/mohamedasifa/Desktop/SheetGeneration/codeforces_ALL_USERS_COMPLETE.csv\"   # <-- change this file name/path\n",
    "COL = \"Username\"\n",
    "\n",
    "df = pd.read_csv(HANDLES_PATH)\n",
    "\n",
    "# 3) Clean handles\n",
    "handles = (\n",
    "    df[COL]\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    ")\n",
    "handles = handles[handles != \"\"].drop_duplicates()\n",
    "\n",
    "print(\"Total unique handles available:\", len(handles))\n",
    "\n",
    "# 4) Sample random 3000 (reproducible)\n",
    "users_3k = handles.sample(n=3000, random_state=42).tolist()\n",
    "\n",
    "# 5) Save\n",
    "out_path = \"cf_dataset_ml/users_3k.csv\"\n",
    "pd.Series(users_3k, name=\"user_id\").to_csv(out_path, index=False)\n",
    "\n",
    "print(\"âœ… Saved:\", out_path, \"| Count:\", len(users_3k))\n",
    "print(\"Example handles:\", users_3k[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6828febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users loaded: 3000\n",
      "ðŸ“¥ Loading problem metadata (problemset.problems)...\n",
      "âœ… Metadata loaded: 10994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1: building problem_attempt_history: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [2:50:37<00:00,  3.41s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Saved: cf_dataset_ml/problem_attempt_history.csv\n",
      "Total rows (user-problem): 370645\n",
      "Unique users in output: 2989\n",
      "Example rows:\n",
      "        user_id  contest_id problem_index problem_key        problem_name  \\\n",
      "0  Ravinder2000           4             A         4-A          Watermelon   \n",
      "1  Ravinder2000          71             A        71-A  Way Too Long Words   \n",
      "2  Ravinder2000         118             A       118-A         String Task   \n",
      "\n",
      "   problem_rating                         topics  \\\n",
      "0           800.0        [\"brute force\", \"math\"]   \n",
      "1           800.0                    [\"strings\"]   \n",
      "2          1000.0  [\"implementation\", \"strings\"]   \n",
      "\n",
      "                        raw_tags  first_submission_time  first_ok_time  \\\n",
      "0        [\"brute force\", \"math\"]             1601488387   1.601488e+09   \n",
      "1                    [\"strings\"]             1601488841   1.623349e+09   \n",
      "2  [\"implementation\", \"strings\"]             1623351809   1.623352e+09   \n",
      "\n",
      "   total_submissions  submissions_until_ok  solved  time_to_first_ac  \n",
      "0                  2                   2.0       1             104.0  \n",
      "1                  3                   3.0       1        21860354.0  \n",
      "2                  4                   3.0       1             359.0  \n",
      "\n",
      "âš ï¸ Some users failed. Saved: cf_dataset_ml/failed_users_step1.csv | Count: 11\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "BASE = \"https://codeforces.com/api/\"\n",
    "REQUEST_SLEEP = 2.1          # IMPORTANT for CF API rate limit \n",
    "MAX_SUBS_PER_USER = None     # Set e.g. 4000 to speed up (optional)\n",
    "OUT_DIR = \"cf_dataset_ml\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Load Top15 topic vocabulary\n",
    "# -----------------------------\n",
    "top15_df = pd.read_csv(\"cf_dataset_v2_fixed/submissions_clean_top15.csv\")\n",
    "TOP15 = list(top15_df[\"topic\"].value_counts().index)\n",
    "TOP15_SET = set(TOP15)\n",
    "\n",
    "# -----------------------------\n",
    "# Load sampled users\n",
    "# -----------------------------\n",
    "USERS = pd.read_csv(\"cf_dataset_ml/users_3k.csv\")[\"user_id\"].dropna().astype(str).tolist()\n",
    "print(\"Users loaded:\", len(USERS))\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def cf_get(endpoint, params=None, retries=6):\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    url = BASE + endpoint\n",
    "    last = None\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=30)\n",
    "            data = r.json()\n",
    "            if data.get(\"status\") == \"OK\":\n",
    "                return data[\"result\"]\n",
    "            last = data\n",
    "            # backoff\n",
    "            time.sleep(min(30, 2 + attempt * 3))\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            time.sleep(min(30, 2 + attempt * 3))\n",
    "\n",
    "    raise Exception(f\"Codeforces API failed: {last}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Fetch problem metadata once\n",
    "# -----------------------------\n",
    "print(\"ðŸ“¥ Loading problem metadata (problemset.problems)...\")\n",
    "ps = cf_get(\"problemset.problems\")  # returns dict with \"problems\" and \"problemStatistics\"\n",
    "problems = ps[\"problems\"]\n",
    "\n",
    "prob_meta = {}\n",
    "for p in problems:\n",
    "    cid = p.get(\"contestId\")\n",
    "    idx = p.get(\"index\")\n",
    "    if cid is None or idx is None:\n",
    "        continue\n",
    "    prob_meta[(cid, idx)] = {\n",
    "        \"problem_name\": p.get(\"name\"),\n",
    "        \"tags\": p.get(\"tags\", []) or [],\n",
    "        \"problem_rating\": p.get(\"rating\", None)\n",
    "    }\n",
    "\n",
    "print(\"âœ… Metadata loaded:\", len(prob_meta))\n",
    "\n",
    "# -----------------------------\n",
    "# Build problem_attempt_history\n",
    "# -----------------------------\n",
    "rows = []\n",
    "failures = []\n",
    "\n",
    "for user in tqdm(USERS, desc=\"Step 1: building problem_attempt_history\"):\n",
    "    try:\n",
    "        subs = cf_get(\"user.status\", {\"handle\": user})\n",
    "    except Exception as e:\n",
    "        failures.append((user, str(e)))\n",
    "        continue\n",
    "\n",
    "    subs = sorted(subs, key=lambda x: x.get(\"creationTimeSeconds\", 0))  # oldest->newest\n",
    "    if MAX_SUBS_PER_USER:\n",
    "        subs = subs[-MAX_SUBS_PER_USER:]\n",
    "\n",
    "    per_problem = {}  # (contest_id, index) -> stats\n",
    "\n",
    "    for s in subs:\n",
    "        cid = s.get(\"contestId\")\n",
    "        prob = s.get(\"problem\", {}) or {}\n",
    "        idx = prob.get(\"index\")\n",
    "        verdict = s.get(\"verdict\")\n",
    "        ts = s.get(\"creationTimeSeconds\")\n",
    "\n",
    "        if cid is None or idx is None or ts is None:\n",
    "            continue\n",
    "\n",
    "        key = (cid, idx)\n",
    "        meta = prob_meta.get(key, {\n",
    "            \"problem_name\": prob.get(\"name\", None),\n",
    "            \"tags\": prob.get(\"tags\", []) or [],\n",
    "            \"problem_rating\": prob.get(\"rating\", None),\n",
    "        })\n",
    "\n",
    "        tags = meta.get(\"tags\", []) or []\n",
    "        topics = [t for t in tags if t in TOP15_SET]\n",
    "        if not topics:\n",
    "            topics = [\"other\"] if \"other\" in TOP15_SET else []\n",
    "        if not topics:\n",
    "            continue\n",
    "\n",
    "        if key not in per_problem:\n",
    "            per_problem[key] = {\n",
    "                \"user_id\": user,\n",
    "                \"contest_id\": cid,\n",
    "                \"problem_index\": idx,\n",
    "                \"problem_key\": f\"{cid}-{idx}\",\n",
    "                \"problem_name\": meta.get(\"problem_name\"),\n",
    "                \"problem_rating\": meta.get(\"problem_rating\"),\n",
    "                \"topics\": json.dumps(topics),  # JSON-safe\n",
    "                \"raw_tags\": json.dumps(tags),  # JSON-safe\n",
    "                \"first_submission_time\": ts,\n",
    "                \"first_ok_time\": None,\n",
    "                \"total_submissions\": 0,\n",
    "                \"submissions_until_ok\": None,\n",
    "                \"solved\": 0\n",
    "            }\n",
    "\n",
    "        st = per_problem[key]\n",
    "        st[\"total_submissions\"] += 1\n",
    "\n",
    "        if verdict == \"OK\" and st[\"first_ok_time\"] is None:\n",
    "            st[\"first_ok_time\"] = ts\n",
    "            st[\"solved\"] = 1\n",
    "            st[\"submissions_until_ok\"] = st[\"total_submissions\"]\n",
    "\n",
    "    for st in per_problem.values():\n",
    "        if st[\"first_ok_time\"] is not None:\n",
    "            st[\"time_to_first_ac\"] = st[\"first_ok_time\"] - st[\"first_submission_time\"]\n",
    "        else:\n",
    "            st[\"time_to_first_ac\"] = None\n",
    "        rows.append(st)\n",
    "\n",
    "    time.sleep(REQUEST_SLEEP)\n",
    "\n",
    "hist = pd.DataFrame(rows)\n",
    "\n",
    "out_path = \"cf_dataset_ml/problem_attempt_history.csv\"\n",
    "hist.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"\\nâœ… Saved:\", out_path)\n",
    "print(\"Total rows (user-problem):\", len(hist))\n",
    "print(\"Unique users in output:\", hist[\"user_id\"].nunique())\n",
    "print(\"Example rows:\")\n",
    "print(hist.head(3))\n",
    "\n",
    "if failures:\n",
    "    fail_path = \"cf_dataset_ml/failed_users_step1.csv\"\n",
    "    pd.DataFrame(failures, columns=[\"user_id\", \"error\"]).to_csv(fail_path, index=False)\n",
    "    print(\"\\nâš ï¸ Some users failed. Saved:\", fail_path, \"| Count:\", len(failures))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6d111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: cf_dataset_ml/user_topic_features_ml.csv\n",
      "Rows: 44835 | Users: 2989 | Topics per user: 15\n",
      "      user_id                    topic  attempted_unique  solved_unique  \\\n",
      "0  -BALERION-                     math                20             15   \n",
      "1  -BALERION-                   greedy                20             17   \n",
      "2  -BALERION-           implementation                11             10   \n",
      "3  -BALERION-                       dp                 4              1   \n",
      "4  -BALERION-          data structures                 1              1   \n",
      "5  -BALERION-                    other                 3              3   \n",
      "6  -BALERION-              brute force                 5              5   \n",
      "7  -BALERION-  constructive algorithms                10              7   \n",
      "8  -BALERION-                   graphs                 1              0   \n",
      "9  -BALERION-            binary search                 2              1   \n",
      "\n",
      "   submissions  accuracy_unique  struggle_score  median_time_to_first_ac  \\\n",
      "0           34         0.750000            1.70                      0.0   \n",
      "1           37         0.850000            1.85                      0.0   \n",
      "2           22         0.909091            2.00                      0.0   \n",
      "3            5         0.250000            1.25                    161.0   \n",
      "4            4         1.000000            4.00                    450.0   \n",
      "5            9         1.000000            3.00                    174.0   \n",
      "6            7         1.000000            1.40                      0.0   \n",
      "7           24         0.700000            2.40                      0.0   \n",
      "8            1         0.000000            1.00                      NaN   \n",
      "9            3         0.500000            1.50                   2121.0   \n",
      "\n",
      "  topic_state  \n",
      "0      STRONG  \n",
      "1      STRONG  \n",
      "2      STRONG  \n",
      "3      MEDIUM  \n",
      "4      MEDIUM  \n",
      "5      MEDIUM  \n",
      "6      STRONG  \n",
      "7      STRONG  \n",
      "8      MEDIUM  \n",
      "9      MEDIUM  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# -----------------------------\n",
    "# Load TOP15 topic vocabulary\n",
    "# -----------------------------\n",
    "top15_df = pd.read_csv(\"cf_dataset_v2_fixed/submissions_clean_top15.csv\")\n",
    "TOP15 = list(top15_df[\"topic\"].value_counts().index)\n",
    "\n",
    "# -----------------------------\n",
    "# Load problem-level history\n",
    "# -----------------------------\n",
    "hist = pd.read_csv(\"cf_dataset_ml/problem_attempt_history.csv\")\n",
    "\n",
    "# Parse topics JSON string -> list\n",
    "hist[\"topics\"] = hist[\"topics\"].apply(lambda x: json.loads(x) if isinstance(x, str) else [])\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for user_id, g in hist.groupby(\"user_id\"):\n",
    "    # multi-label explode\n",
    "    g_exp = g.explode(\"topics\").rename(columns={\"topics\": \"topic\"})\n",
    "    g_exp = g_exp[g_exp[\"topic\"].isin(TOP15)]\n",
    "\n",
    "    attempted = g_exp.groupby(\"topic\").size()\n",
    "    solved = g_exp[g_exp[\"solved\"] == 1].groupby(\"topic\").size()\n",
    "    submissions = g_exp.groupby(\"topic\")[\"total_submissions\"].sum()\n",
    "\n",
    "    # median time to first AC among solved problems\n",
    "    tta = (\n",
    "        g_exp[g_exp[\"time_to_first_ac\"].notna()]\n",
    "        .groupby(\"topic\")[\"time_to_first_ac\"]\n",
    "        .median()\n",
    "    )\n",
    "\n",
    "    # include attempt=0 topics too\n",
    "    for t in TOP15:\n",
    "        a = int(attempted.get(t, 0))\n",
    "        s = int(solved.get(t, 0))\n",
    "        sub = int(submissions.get(t, 0))\n",
    "        acc = (s / a) if a > 0 else 0.0\n",
    "        struggle = (sub / a) if a > 0 else 0.0\n",
    "        med_tta = float(tta.get(t, np.nan)) if t in tta.index else np.nan\n",
    "\n",
    "        all_rows.append({\n",
    "            \"user_id\": user_id,\n",
    "            \"topic\": t,\n",
    "            \"attempted_unique\": a,\n",
    "            \"solved_unique\": s,\n",
    "            \"submissions\": sub,\n",
    "            \"accuracy_unique\": acc,\n",
    "            \"struggle_score\": struggle,\n",
    "            \"median_time_to_first_ac\": med_tta\n",
    "        })\n",
    "\n",
    "feat = pd.DataFrame(all_rows)\n",
    "\n",
    "# -----------------------------\n",
    "# Topic state labeling (robust)\n",
    "# - avoid \"1/1 = STRONG\" issue by requiring min attempts\n",
    "# -----------------------------\n",
    "def label_topic_state(row, med_attempts):\n",
    "    a = row[\"attempted_unique\"]\n",
    "    acc = row[\"accuracy_unique\"]\n",
    "\n",
    "    if a == 0:\n",
    "        return \"MEDIUM\"\n",
    "    if a >= max(5, med_attempts) and acc < 0.45:\n",
    "        return \"WEAK\"\n",
    "    if a >= 5 and acc >= 0.70:\n",
    "        return \"STRONG\"\n",
    "    return \"MEDIUM\"\n",
    "\n",
    "feat[\"topic_state\"] = \"MEDIUM\"\n",
    "for user_id, g in feat.groupby(\"user_id\"):\n",
    "    med_attempts = int(g[\"attempted_unique\"].median())\n",
    "    feat.loc[g.index, \"topic_state\"] = g.apply(lambda r: label_topic_state(r, med_attempts), axis=1)\n",
    "\n",
    "# Save\n",
    "out_path = \"cf_dataset_ml/user_topic_features_ml.csv\"\n",
    "feat.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"âœ… Saved:\", out_path)\n",
    "print(\"Rows:\", len(feat), \"| Users:\", feat[\"user_id\"].nunique(), \"| Topics per user:\", feat[\"topic\"].nunique())\n",
    "print(feat.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4bd8992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: cf_dataset_ml/user_topic_weekly_trend_unique.csv\n",
      "Rows: 60244 | Users: 2989\n",
      "      user_id year_week      math    greedy  implementation   dp  \\\n",
      "0  -BALERION-  2025-W50  1.000000  1.000000        1.000000  0.0   \n",
      "1  -BALERION-  2025-W51  1.000000  0.857143        1.000000  0.0   \n",
      "2  -BALERION-  2025-W52  0.875000  0.777778        1.000000  0.5   \n",
      "3  -BALERION-  2026-W01  0.875000  0.800000        1.000000  0.5   \n",
      "4  -BALERION-  2026-W02  0.833333  0.812500        0.888889  0.5   \n",
      "\n",
      "   data structures  other  brute force  constructive algorithms  graphs  \\\n",
      "0              0.0    0.0          1.0                 1.000000     0.0   \n",
      "1              0.0    0.0          1.0                 0.500000     0.0   \n",
      "2              0.0    0.0          1.0                 0.333333     0.0   \n",
      "3              0.0    0.0          1.0                 0.500000     0.0   \n",
      "4              0.0    1.0          1.0                 0.571429     0.0   \n",
      "\n",
      "   binary search  sortings  trees  number theory   strings  geometry  \n",
      "0            0.0       1.0    0.0       0.000000  1.000000       0.0  \n",
      "1            0.0       1.0    0.0       0.500000  1.000000       0.0  \n",
      "2            0.0       1.0    0.0       0.666667  1.000000       0.0  \n",
      "3            0.0       1.0    0.0       0.666667  1.000000       0.0  \n",
      "4            1.0       1.0    0.0       0.750000  0.833333       0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, UTC\n",
    "\n",
    "# -----------------------------\n",
    "# Load TOP15\n",
    "# -----------------------------\n",
    "top15_df = pd.read_csv(\"cf_dataset_v2_fixed/submissions_clean_top15.csv\")\n",
    "TOP15 = list(top15_df[\"topic\"].value_counts().index)\n",
    "\n",
    "# -----------------------------\n",
    "# Load problem-level history\n",
    "# -----------------------------\n",
    "hist = pd.read_csv(\"cf_dataset_ml/problem_attempt_history.csv\")\n",
    "hist[\"topics\"] = hist[\"topics\"].apply(lambda x: json.loads(x) if isinstance(x, str) else [])\n",
    "\n",
    "# -----------------------------\n",
    "# year_week helper\n",
    "# -----------------------------\n",
    "def year_week_from_ts(ts):\n",
    "    dt = datetime.fromtimestamp(int(ts), UTC)  # timezone-aware UTC\n",
    "    y, w, _ = dt.isocalendar()\n",
    "    return f\"{y}-W{w:02d}\"\n",
    "\n",
    "hist[\"year_week\"] = hist[\"first_submission_time\"].apply(year_week_from_ts)\n",
    "\n",
    "# -----------------------------\n",
    "# Build weekly cumulative accuracy snapshots\n",
    "# -----------------------------\n",
    "rows = []\n",
    "\n",
    "for user_id, g in hist.groupby(\"user_id\"):\n",
    "    g = g.sort_values(\"first_submission_time\")\n",
    "\n",
    "    # multi-label explode\n",
    "    g_exp = g.explode(\"topics\").rename(columns={\"topics\": \"topic\"})\n",
    "    g_exp = g_exp[g_exp[\"topic\"].isin(TOP15)]\n",
    "\n",
    "    attempted = {t: set() for t in TOP15}\n",
    "    solved = {t: set() for t in TOP15}\n",
    "\n",
    "    weekly_records = {}  # year_week -> {topic: acc}\n",
    "\n",
    "    for _, row in g_exp.iterrows():\n",
    "        t = row[\"topic\"]\n",
    "        prob_key = (int(row[\"contest_id\"]), str(row[\"problem_index\"]))\n",
    "        yw = row[\"year_week\"]\n",
    "\n",
    "        attempted[t].add(prob_key)\n",
    "        if int(row[\"solved\"]) == 1:\n",
    "            solved[t].add(prob_key)\n",
    "\n",
    "        if yw not in weekly_records:\n",
    "            weekly_records[yw] = {}\n",
    "\n",
    "        # snapshot for ALL topics at this week\n",
    "        for topic in TOP15:\n",
    "            a = len(attempted[topic])\n",
    "            s = len(solved[topic])\n",
    "            weekly_records[yw][topic] = (s / a) if a > 0 else 0.0\n",
    "\n",
    "    # convert to rows\n",
    "    for yw, topic_accs in weekly_records.items():\n",
    "        rec = {\"user_id\": user_id, \"year_week\": yw}\n",
    "        rec.update(topic_accs)\n",
    "        rows.append(rec)\n",
    "\n",
    "trend = pd.DataFrame(rows)\n",
    "\n",
    "# -----------------------------\n",
    "# Sort year_week correctly\n",
    "# -----------------------------\n",
    "def parse_yw(s):\n",
    "    y, w = s.split(\"-W\")\n",
    "    return int(y), int(w)\n",
    "\n",
    "trend[[\"yw_year\", \"yw_week\"]] = trend[\"year_week\"].apply(lambda x: pd.Series(parse_yw(x)))\n",
    "trend = trend.sort_values([\"user_id\", \"yw_year\", \"yw_week\"]).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Forward fill per user\n",
    "# -----------------------------\n",
    "trend[TOP15] = trend.groupby(\"user_id\")[TOP15].ffill().fillna(0.0)\n",
    "\n",
    "trend = trend.drop(columns=[\"yw_year\", \"yw_week\"])\n",
    "\n",
    "# Save\n",
    "out_path = \"cf_dataset_ml/user_topic_weekly_trend_unique.csv\"\n",
    "trend.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"âœ… Saved:\", out_path)\n",
    "print(\"Rows:\", len(trend), \"| Users:\", trend[\"user_id\"].nunique())\n",
    "print(trend.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913993cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 3000\n",
      "âœ… Saved cf_dataset_ml/user_profile.csv | Rows: 3000\n",
      "âœ… Saved cf_dataset_ml/training_feature_columns_v2.txt\n",
      "K=2, Silhouette=0.2234\n",
      "K=3, Silhouette=0.2210\n",
      "K=4, Silhouette=0.1656\n",
      "K=5, Silhouette=0.1651\n",
      "K=6, Silhouette=0.1524\n",
      "K=7, Silhouette=0.1548\n",
      "âœ… Best K: 2\n",
      "âœ… Saved cf_dataset_ml/user_clusters_v2.csv\n",
      "âœ… Saved cf_dataset_ml/scaler_v2.pkl and cf_dataset_ml/kmeans_v2.pkl\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "BASE = \"https://codeforces.com/api/\"\n",
    "REQUEST_SLEEP = 2.1  # CF limit \n",
    "\n",
    "# -----------------------------\n",
    "# Load TOP15\n",
    "# -----------------------------\n",
    "top15_df = pd.read_csv(\"cf_dataset_v2_fixed/submissions_clean_top15.csv\")\n",
    "TOP15 = list(top15_df[\"topic\"].value_counts().index)\n",
    "\n",
    "# -----------------------------\n",
    "# Load features + trend\n",
    "# -----------------------------\n",
    "feat = pd.read_csv(\"cf_dataset_ml/user_topic_features_ml.csv\")\n",
    "trend = pd.read_csv(\"cf_dataset_ml/user_topic_weekly_trend_unique.csv\")\n",
    "\n",
    "# Users list (same 3k)\n",
    "users = pd.read_csv(\"cf_dataset_ml/users_3k.csv\")[\"user_id\"].dropna().astype(str).tolist()\n",
    "print(\"Users:\", len(users))\n",
    "\n",
    "# -----------------------------\n",
    "# CF helper\n",
    "# -----------------------------\n",
    "def cf_get(endpoint, params=None, retries=6):\n",
    "    if params is None: params = {}\n",
    "    url = BASE + endpoint\n",
    "    last = None\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=30)\n",
    "            data = r.json()\n",
    "            if data.get(\"status\") == \"OK\":\n",
    "                return data[\"result\"]\n",
    "            last = data\n",
    "            time.sleep(min(30, 2 + attempt * 3))\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            time.sleep(min(30, 2 + attempt * 3))\n",
    "    raise Exception(f\"API failed: {last}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Fetch user profiles (rating) in chunks\n",
    "# -----------------------------\n",
    "profiles = []\n",
    "chunk_size = 400  # safe URL length\n",
    "for i in range(0, len(users), chunk_size):\n",
    "    chunk = users[i:i+chunk_size]\n",
    "    res = cf_get(\"user.info\", {\"handles\": \";\".join(chunk)})\n",
    "\n",
    "    for u in res:\n",
    "        profiles.append({\n",
    "            \"user_id\": u.get(\"handle\"),\n",
    "            \"rating\": u.get(\"rating\", 0),\n",
    "            \"max_rating\": u.get(\"maxRating\", 0),\n",
    "            \"rank\": u.get(\"rank\", \"\"),\n",
    "            \"max_rank\": u.get(\"maxRank\", \"\")\n",
    "        })\n",
    "\n",
    "    time.sleep(REQUEST_SLEEP)\n",
    "\n",
    "profile = pd.DataFrame(profiles)\n",
    "profile.to_csv(\"cf_dataset_ml/user_profile.csv\", index=False)\n",
    "print(\"âœ… Saved cf_dataset_ml/user_profile.csv | Rows:\", len(profile))\n",
    "\n",
    "# -----------------------------\n",
    "# Trend slope per user\n",
    "# -----------------------------\n",
    "def compute_trend_slope(g):\n",
    "    topic_cols = [c for c in g.columns if c not in [\"user_id\", \"year_week\"]]\n",
    "    g = g.sort_values(\"year_week\")\n",
    "    y = g[topic_cols].mean(axis=1).values\n",
    "    if len(y) < 2:\n",
    "        return 0.0\n",
    "    x = np.arange(len(y))\n",
    "    return np.polyfit(x, y, 1)[0]\n",
    "\n",
    "trend_slope = (\n",
    "    trend.groupby(\"user_id\")\n",
    "    .apply(compute_trend_slope)\n",
    "    .reset_index(name=\"trend_slope\")\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Pivot topic features wide\n",
    "# -----------------------------\n",
    "def pivot_feature(df, colname):\n",
    "    p = df.pivot(index=\"user_id\", columns=\"topic\", values=colname)\n",
    "    p.columns = [f\"{colname}_{c}\" for c in p.columns]\n",
    "    return p\n",
    "\n",
    "acc_pivot = pivot_feature(feat, \"accuracy_unique\")\n",
    "cov_pivot = pivot_feature(feat, \"attempted_unique\")\n",
    "str_pivot = pivot_feature(feat, \"struggle_score\")\n",
    "\n",
    "X = acc_pivot.join(cov_pivot).join(str_pivot).reset_index()\n",
    "\n",
    "# Add rating + trend_slope\n",
    "X = X.merge(profile[[\"user_id\", \"rating\"]], on=\"user_id\", how=\"left\")\n",
    "X = X.merge(trend_slope, on=\"user_id\", how=\"left\")\n",
    "\n",
    "X = X.fillna(0)\n",
    "\n",
    "user_ids = X[\"user_id\"]\n",
    "X_vals = X.drop(columns=[\"user_id\"])\n",
    "\n",
    "# -----------------------------\n",
    "# Save feature column order for inference\n",
    "# -----------------------------\n",
    "with open(\"cf_dataset_ml/training_feature_columns_v2.txt\", \"w\") as f:\n",
    "    for c in X_vals.columns:\n",
    "        f.write(c + \"\\n\")\n",
    "print(\"âœ… Saved cf_dataset_ml/training_feature_columns_v2.txt\")\n",
    "\n",
    "# -----------------------------\n",
    "# Scale + choose best K\n",
    "# -----------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_vals)\n",
    "\n",
    "best_k, best_score = 2, -1\n",
    "for k in range(2, 8):\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels)\n",
    "    print(f\"K={k}, Silhouette={score:.4f}\")\n",
    "    if score > best_score:\n",
    "        best_score, best_k = score, k\n",
    "\n",
    "print(\"âœ… Best K:\", best_k)\n",
    "\n",
    "# -----------------------------\n",
    "# Final clustering\n",
    "# -----------------------------\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "cluster_df = pd.DataFrame({\n",
    "    \"user_id\": user_ids,\n",
    "    \"cluster\": [f\"C{c}\" for c in clusters]\n",
    "})\n",
    "cluster_df.to_csv(\"cf_dataset_ml/user_clusters_v2.csv\", index=False)\n",
    "print(\"âœ… Saved cf_dataset_ml/user_clusters_v2.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save artifacts\n",
    "# -----------------------------\n",
    "joblib.dump(scaler, \"cf_dataset_ml/scaler_v2.pkl\")\n",
    "joblib.dump(kmeans, \"cf_dataset_ml/kmeans_v2.pkl\")\n",
    "print(\"âœ… Saved cf_dataset_ml/scaler_v2.pkl and cf_dataset_ml/kmeans_v2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff16a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: cf_dataset_ml/cluster_topic_problem_stats.csv\n",
      "Rows: 48647 | Clusters: 2 | Topics: 15\n",
      "  cluster          topic problem_key  contest_id problem_index  \\\n",
      "0      C0  binary search      1004-E        1004             E   \n",
      "1      C0  binary search      1006-C        1006             C   \n",
      "2      C0  binary search      1007-C        1007             C   \n",
      "3      C0  binary search      1008-E        1008             E   \n",
      "4      C0  binary search       101-B         101             B   \n",
      "\n",
      "               problem_name  problem_rating  attempt_users  solve_users  \\\n",
      "0       Sonya and Ice Cream          2400.0              3            1   \n",
      "1  Three Parts of the Array          1200.0             66           63   \n",
      "2         Guess two numbers          3000.0              3            3   \n",
      "3         Guess two numbers          3000.0              2            1   \n",
      "4                     Buses          1700.0              7            6   \n",
      "\n",
      "   median_submissions_until_ok  median_time_to_first_ac  success_rate  \\\n",
      "0                          1.0                      0.0      0.333333   \n",
      "1                          2.0                    318.0      0.954545   \n",
      "2                          1.0                      0.0      1.000000   \n",
      "3                         12.0                  47929.0      0.500000   \n",
      "4                          1.5                     44.5      0.857143   \n",
      "\n",
      "                                         cf_link  \n",
      "0  https://codeforces.com/contest/1004/problem/E  \n",
      "1  https://codeforces.com/contest/1006/problem/C  \n",
      "2  https://codeforces.com/contest/1007/problem/C  \n",
      "3  https://codeforces.com/contest/1008/problem/E  \n",
      "4   https://codeforces.com/contest/101/problem/B  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Load problem history + clusters\n",
    "# -----------------------------\n",
    "hist = pd.read_csv(\"cf_dataset_ml/problem_attempt_history.csv\")\n",
    "hist[\"topics\"] = hist[\"topics\"].apply(lambda x: json.loads(x) if isinstance(x, str) else [])\n",
    "\n",
    "clusters = pd.read_csv(\"cf_dataset_ml/user_clusters_v2.csv\")\n",
    "\n",
    "# attach cluster to each user-problem row\n",
    "hist = hist.merge(clusters, on=\"user_id\", how=\"left\")\n",
    "hist = hist[hist[\"cluster\"].notna()].copy()\n",
    "\n",
    "# explode topics (multi-label)\n",
    "df = hist.explode(\"topics\").rename(columns={\"topics\": \"topic\"})\n",
    "df[\"problem_key\"] = df[\"contest_id\"].astype(str) + \"-\" + df[\"problem_index\"].astype(str)\n",
    "\n",
    "# -----------------------------\n",
    "# Compute stats\n",
    "# -----------------------------\n",
    "attempt_users = df.groupby([\"cluster\",\"topic\",\"problem_key\"])[\"user_id\"].nunique().rename(\"attempt_users\")\n",
    "\n",
    "solve_users = (\n",
    "    df[df[\"solved\"] == 1]\n",
    "    .groupby([\"cluster\",\"topic\",\"problem_key\"])[\"user_id\"]\n",
    "    .nunique()\n",
    "    .rename(\"solve_users\")\n",
    ")\n",
    "\n",
    "med_sub_until_ok = (\n",
    "    df[df[\"solved\"] == 1]\n",
    "    .groupby([\"cluster\",\"topic\",\"problem_key\"])[\"submissions_until_ok\"]\n",
    "    .median()\n",
    "    .rename(\"median_submissions_until_ok\")\n",
    ")\n",
    "\n",
    "med_time_to_ac = (\n",
    "    df[df[\"solved\"] == 1]\n",
    "    .groupby([\"cluster\",\"topic\",\"problem_key\"])[\"time_to_first_ac\"]\n",
    "    .median()\n",
    "    .rename(\"median_time_to_first_ac\")\n",
    ")\n",
    "\n",
    "meta = (\n",
    "    df.groupby([\"cluster\",\"topic\",\"problem_key\"], as_index=False)\n",
    "    .agg(\n",
    "        contest_id=(\"contest_id\",\"first\"),\n",
    "        problem_index=(\"problem_index\",\"first\"),\n",
    "        problem_name=(\"problem_name\",\"first\"),\n",
    "        problem_rating=(\"problem_rating\",\"first\")\n",
    "    )\n",
    "    .set_index([\"cluster\",\"topic\",\"problem_key\"])\n",
    ")\n",
    "\n",
    "stats = meta.join(attempt_users).join(solve_users).join(med_sub_until_ok).join(med_time_to_ac).reset_index()\n",
    "\n",
    "stats[\"attempt_users\"] = stats[\"attempt_users\"].fillna(0).astype(int)\n",
    "stats[\"solve_users\"] = stats[\"solve_users\"].fillna(0).astype(int)\n",
    "\n",
    "stats[\"success_rate\"] = stats.apply(\n",
    "    lambda r: (r[\"solve_users\"] / r[\"attempt_users\"]) if r[\"attempt_users\"] > 0 else 0.0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Add problem link\n",
    "stats[\"cf_link\"] = stats.apply(\n",
    "    lambda r: f\"https://codeforces.com/contest/{int(r['contest_id'])}/problem/{r['problem_index']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save\n",
    "out_path = \"cf_dataset_ml/cluster_topic_problem_stats.csv\"\n",
    "stats.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"âœ… Saved:\", out_path)\n",
    "print(\"Rows:\", len(stats), \"| Clusters:\", stats[\"cluster\"].nunique(), \"| Topics:\", stats[\"topic\"].nunique())\n",
    "print(stats.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e15ea47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading problem metadata (problemset.problems)...\n",
      "âœ… Metadata loaded: 10993\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, UTC\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "BASE = \"https://codeforces.com/api/\"\n",
    "REQUEST_SLEEP = 2.1  # CF limit \n",
    "MAX_SUBS_PER_USER = None  # optional cap for speed\n",
    "\n",
    "# -----------------------------\n",
    "# Load TOP15\n",
    "# -----------------------------\n",
    "top15_df = pd.read_csv(\"cf_dataset_v2_fixed/submissions_clean_top15.csv\")\n",
    "TOP15 = list(top15_df[\"topic\"].value_counts().index)\n",
    "TOP15_SET = set(TOP15)\n",
    "\n",
    "# -----------------------------\n",
    "# Load artifacts\n",
    "# -----------------------------\n",
    "scaler = joblib.load(\"cf_dataset_ml/scaler_v2.pkl\")\n",
    "kmeans = joblib.load(\"cf_dataset_ml/kmeans_v2.pkl\")\n",
    "stats  = pd.read_csv(\"cf_dataset_ml/cluster_topic_problem_stats.csv\")\n",
    "\n",
    "with open(\"cf_dataset_ml/training_feature_columns_v2.txt\", \"r\") as f:\n",
    "    FEATURE_COLS = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# -----------------------------\n",
    "# CF helper\n",
    "# -----------------------------\n",
    "def cf_get(endpoint, params=None, retries=6):\n",
    "    if params is None: params = {}\n",
    "    url = BASE + endpoint\n",
    "    last = None\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=30)\n",
    "            data = r.json()\n",
    "            if data.get(\"status\") == \"OK\":\n",
    "                return data[\"result\"]\n",
    "            last = data\n",
    "            time.sleep(min(30, 2 + attempt * 3))\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "            time.sleep(min(30, 2 + attempt * 3))\n",
    "    raise Exception(f\"API failed: {last}\")\n",
    "\n",
    "def align_columns(vec_df):\n",
    "    for c in FEATURE_COLS:\n",
    "        if c not in vec_df.columns:\n",
    "            vec_df[c] = 0.0\n",
    "    return vec_df[FEATURE_COLS]\n",
    "\n",
    "def year_week_from_ts(ts):\n",
    "    dt = datetime.fromtimestamp(int(ts), UTC)\n",
    "    y, w, _ = dt.isocalendar()\n",
    "    return f\"{y}-W{w:02d}\"\n",
    "\n",
    "# -----------------------------\n",
    "# Load problem metadata once\n",
    "# -----------------------------\n",
    "print(\"ðŸ“¥ Loading problem metadata (problemset.problems)...\")\n",
    "ps = cf_get(\"problemset.problems\")\n",
    "prob_meta = {(p[\"contestId\"], p[\"index\"]): {\n",
    "    \"problem_name\": p.get(\"name\"),\n",
    "    \"tags\": p.get(\"tags\", []) or [],\n",
    "    \"problem_rating\": p.get(\"rating\", None)\n",
    "} for p in ps[\"problems\"]}\n",
    "print(\"âœ… Metadata loaded:\", len(prob_meta))\n",
    "\n",
    "# -----------------------------\n",
    "# A) Platform tag counts (unique solved problems)\n",
    "# -----------------------------\n",
    "def print_codeforces_platform_tag_counts(handle, top_k=30):\n",
    "    subs = cf_get(\"user.status\", {\"handle\": handle})\n",
    "\n",
    "    solved_problems = set()\n",
    "    tag_counter = {}\n",
    "\n",
    "    for s in subs:\n",
    "        if s.get(\"verdict\") != \"OK\":\n",
    "            continue\n",
    "        prob = s.get(\"problem\", {}) or {}\n",
    "        cid = prob.get(\"contestId\")\n",
    "        idx = prob.get(\"index\")\n",
    "        tags = prob.get(\"tags\", []) or []\n",
    "        if cid is None or idx is None:\n",
    "            continue\n",
    "\n",
    "        key = (cid, idx)\n",
    "        if key in solved_problems:\n",
    "            continue\n",
    "        solved_problems.add(key)\n",
    "\n",
    "        for t in tags:\n",
    "            tag_counter[t] = tag_counter.get(t, 0) + 1\n",
    "\n",
    "    sorted_tags = sorted(tag_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\n--- Codeforces Platform Tag Counts (unique solved problems) ---\")\n",
    "    for t, c in sorted_tags[:top_k]:\n",
    "        print(f\"{t:25s} : {c}\")\n",
    "\n",
    "# -----------------------------\n",
    "# B) Build new user's problem history (problem-level, multi-label TOP15)\n",
    "# -----------------------------\n",
    "def build_new_user_problem_history(handle, limit=MAX_SUBS_PER_USER):\n",
    "    subs = cf_get(\"user.status\", {\"handle\": handle})\n",
    "    subs = sorted(subs, key=lambda x: x.get(\"creationTimeSeconds\", 0))  # oldest->newest\n",
    "    if limit:\n",
    "        subs = subs[-limit:]\n",
    "\n",
    "    per_problem = {}\n",
    "    for s in subs:\n",
    "        cid = s.get(\"contestId\")\n",
    "        prob = s.get(\"problem\", {}) or {}\n",
    "        idx = prob.get(\"index\")\n",
    "        verdict = s.get(\"verdict\")\n",
    "        ts = s.get(\"creationTimeSeconds\")\n",
    "\n",
    "        if cid is None or idx is None or ts is None:\n",
    "            continue\n",
    "\n",
    "        key = (cid, idx)\n",
    "        meta = prob_meta.get(key, {\n",
    "            \"problem_name\": prob.get(\"name\"),\n",
    "            \"tags\": prob.get(\"tags\", []) or [],\n",
    "            \"problem_rating\": prob.get(\"rating\", None)\n",
    "        })\n",
    "\n",
    "        tags = meta.get(\"tags\", []) or []\n",
    "        topics = [t for t in tags if t in TOP15_SET]\n",
    "        if not topics:\n",
    "            topics = [\"other\"] if \"other\" in TOP15_SET else []\n",
    "        if not topics:\n",
    "            continue\n",
    "\n",
    "        if key not in per_problem:\n",
    "            per_problem[key] = {\n",
    "                \"contest_id\": cid,\n",
    "                \"problem_index\": idx,\n",
    "                \"problem_key\": f\"{cid}-{idx}\",\n",
    "                \"problem_name\": meta.get(\"problem_name\"),\n",
    "                \"problem_rating\": meta.get(\"problem_rating\"),\n",
    "                \"topics\": topics,\n",
    "                \"first_submission_time\": ts,\n",
    "                \"first_ok_time\": None,\n",
    "                \"total_submissions\": 0,\n",
    "                \"submissions_until_ok\": None,\n",
    "                \"solved\": 0,\n",
    "                \"year_week\": year_week_from_ts(ts)\n",
    "            }\n",
    "\n",
    "        st = per_problem[key]\n",
    "        st[\"total_submissions\"] += 1\n",
    "\n",
    "        if verdict == \"OK\" and st[\"first_ok_time\"] is None:\n",
    "            st[\"first_ok_time\"] = ts\n",
    "            st[\"solved\"] = 1\n",
    "            st[\"submissions_until_ok\"] = st[\"total_submissions\"]\n",
    "\n",
    "    for st in per_problem.values():\n",
    "        st[\"time_to_first_ac\"] = (st[\"first_ok_time\"] - st[\"first_submission_time\"]) if st[\"first_ok_time\"] else np.nan\n",
    "\n",
    "    return pd.DataFrame(per_problem.values())\n",
    "\n",
    "# -----------------------------\n",
    "# C) Build topic features table weak->strong (includes attempt=0)\n",
    "# -----------------------------\n",
    "def build_user_topic_features_from_history(problem_hist_df):\n",
    "    g_exp = problem_hist_df.explode(\"topics\").rename(columns={\"topics\":\"topic\"})\n",
    "    g_exp = g_exp[g_exp[\"topic\"].isin(TOP15)]\n",
    "\n",
    "    attempted = g_exp.groupby(\"topic\").size()\n",
    "    solved = g_exp[g_exp[\"solved\"]==1].groupby(\"topic\").size()\n",
    "    submissions = g_exp.groupby(\"topic\")[\"total_submissions\"].sum()\n",
    "\n",
    "    rows=[]\n",
    "    for t in TOP15:\n",
    "        a = int(attempted.get(t, 0))\n",
    "        s = int(solved.get(t, 0))\n",
    "        sub = int(submissions.get(t, 0))\n",
    "        acc = (s/a) if a>0 else 0.0\n",
    "        struggle = (sub/a) if a>0 else 0.0\n",
    "        rows.append({\n",
    "            \"topic\": t,\n",
    "            \"attempted_unique\": a,\n",
    "            \"solved_unique\": s,\n",
    "            \"accuracy_unique\": acc,\n",
    "            \"struggle_score\": struggle\n",
    "        })\n",
    "    out = pd.DataFrame(rows)\n",
    "\n",
    "    med_attempts = int(out[\"attempted_unique\"].median())\n",
    "    def label(r):\n",
    "        a=r[\"attempted_unique\"]; acc=r[\"accuracy_unique\"]\n",
    "        if a==0: return \"MEDIUM\"\n",
    "        if a>=max(5, med_attempts) and acc<0.45: return \"WEAK\"\n",
    "        if a>=5 and acc>=0.70: return \"STRONG\"\n",
    "        return \"MEDIUM\"\n",
    "    out[\"topic_state\"] = out.apply(label, axis=1)\n",
    "\n",
    "    # weak->strong\n",
    "    return out.sort_values([\"accuracy_unique\",\"attempted_unique\"], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# D) Trend slope from history (simple weekly accuracy series)\n",
    "# -----------------------------\n",
    "def compute_trend_slope_from_history(problem_hist_df):\n",
    "    g_exp = problem_hist_df.explode(\"topics\").rename(columns={\"topics\":\"topic\"})\n",
    "    g_exp = g_exp[g_exp[\"topic\"].isin(TOP15)]\n",
    "\n",
    "    weekly = (\n",
    "        g_exp.groupby([\"year_week\",\"topic\"], as_index=False)\n",
    "        .agg(attempted=(\"problem_key\",\"count\"), solved=(\"solved\",\"sum\"))\n",
    "    )\n",
    "    weekly[\"acc\"] = weekly[\"solved\"] / weekly[\"attempted\"]\n",
    "\n",
    "    overall = weekly.groupby(\"year_week\")[\"acc\"].mean().reset_index().sort_values(\"year_week\")\n",
    "    if len(overall) < 2:\n",
    "        return 0.0\n",
    "    y = overall[\"acc\"].values\n",
    "    x = np.arange(len(y))\n",
    "    return float(np.polyfit(x, y, 1)[0])\n",
    "\n",
    "# -----------------------------\n",
    "# E) Build cluster vector (must match Step 4 schema)\n",
    "# -----------------------------\n",
    "def build_cluster_vector(rating, topic_tbl, trend_slope):\n",
    "    row = {\"rating\": float(rating), \"trend_slope\": float(trend_slope)}\n",
    "    for _, r in topic_tbl.iterrows():\n",
    "        t = r[\"topic\"]\n",
    "        row[f\"accuracy_unique_{t}\"] = float(r[\"accuracy_unique\"])\n",
    "        row[f\"attempted_unique_{t}\"] = float(r[\"attempted_unique\"])\n",
    "        row[f\"struggle_score_{t}\"] = float(r[\"struggle_score\"])\n",
    "    return pd.DataFrame([row])\n",
    "\n",
    "# -----------------------------\n",
    "# F) Recommend for one topic (cluster + topic)\n",
    "# -----------------------------\n",
    "def recommend_for_cluster_topic(cluster_label, topic, solved_keys, top_n=5, user_rating=None, rating_band=300):\n",
    "    cand = stats[(stats[\"cluster\"]==cluster_label) & (stats[\"topic\"]==topic)].copy()\n",
    "    cand = cand[~cand[\"problem_key\"].isin(solved_keys)]\n",
    "\n",
    "    # rating band filter (OA-friendly)\n",
    "    if user_rating is not None and \"problem_rating\" in cand.columns:\n",
    "        low, high = user_rating - rating_band, user_rating + rating_band\n",
    "        cand2 = cand[(cand[\"problem_rating\"].notna()) &\n",
    "                     (cand[\"problem_rating\"]>=low) &\n",
    "                     (cand[\"problem_rating\"]<=high)].copy()\n",
    "        if not cand2.empty:\n",
    "            cand = cand2\n",
    "\n",
    "    if cand.empty:\n",
    "        return cand\n",
    "\n",
    "    cand[\"median_submissions_until_ok\"] = cand[\"median_submissions_until_ok\"].fillna(999)\n",
    "    cand[\"median_time_to_first_ac\"] = cand[\"median_time_to_first_ac\"].fillna(10**12)\n",
    "\n",
    "    cand = cand.sort_values(\n",
    "        [\"success_rate\",\"solve_users\",\"median_submissions_until_ok\",\"median_time_to_first_ac\"],\n",
    "        ascending=[False, False, True, True]\n",
    "    ).head(top_n)\n",
    "\n",
    "    return cand[[\"contest_id\",\"problem_index\",\"problem_name\",\"problem_rating\",\"success_rate\",\"solve_users\",\"attempt_users\",\"cf_link\"]]\n",
    "\n",
    "# -----------------------------\n",
    "# G) Full report function\n",
    "# -----------------------------\n",
    "def new_user_report(handle, top_n=5):\n",
    "    # platform counts\n",
    "    print_codeforces_platform_tag_counts(handle, top_k=30)\n",
    "\n",
    "    # rating\n",
    "    info = cf_get(\"user.info\", {\"handles\": handle})[0]\n",
    "    rating = info.get(\"rating\", None)\n",
    "    if rating is None:\n",
    "        raise ValueError(\"User has no rating yet (unrated).\")\n",
    "\n",
    "    # build history + features\n",
    "    hist_df = build_new_user_problem_history(handle)\n",
    "    topic_tbl = build_user_topic_features_from_history(hist_df)\n",
    "    trend_slope = compute_trend_slope_from_history(hist_df)\n",
    "\n",
    "    # cluster prediction\n",
    "    vec = build_cluster_vector(rating, topic_tbl, trend_slope)\n",
    "    vec_aligned = align_columns(vec)\n",
    "\n",
    "    cluster_id = int(kmeans.predict(scaler.transform(vec_aligned))[0])\n",
    "    cluster = f\"C{cluster_id}\"\n",
    "\n",
    "    # solved filter\n",
    "    solved_keys = set(hist_df[hist_df[\"solved\"]==1][\"problem_key\"])\n",
    "\n",
    "    print(f\"\\nUser: {handle} Rating: {int(rating)} Predicted cluster: {cluster}\\n\")\n",
    "\n",
    "    print(\"Topics weak -> strong:\")\n",
    "    print(\n",
    "        topic_tbl[[\"topic\",\"topic_state\",\"accuracy_unique\",\"attempted_unique\"]]\n",
    "        .rename(columns={\"accuracy_unique\":\"accuracy\",\"attempted_unique\":\"attempts\"})\n",
    "        .to_string(index=False)\n",
    "    )\n",
    "\n",
    "    weakest_topic = topic_tbl.iloc[0][\"topic\"]\n",
    "    print(f\"\\nWeakest topic: {weakest_topic}\")\n",
    "\n",
    "    recs = recommend_for_cluster_topic(cluster, weakest_topic, solved_keys, top_n=top_n, user_rating=rating)\n",
    "    if recs.empty:\n",
    "        print(\"No recommendations found (all solved / no candidates).\")\n",
    "    else:\n",
    "        print(recs.to_string(index=False))\n",
    "\n",
    "# Example:\n",
    "# new_user_report(\"mohd_fariq\", top_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a8fa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Codeforces Platform Tag Counts (unique solved problems) ---\n",
      "greedy                    : 141\n",
      "math                      : 101\n",
      "implementation            : 92\n",
      "brute force               : 56\n",
      "constructive algorithms   : 54\n",
      "sortings                  : 42\n",
      "strings                   : 27\n",
      "dp                        : 23\n",
      "binary search             : 22\n",
      "two pointers              : 22\n",
      "number theory             : 16\n",
      "data structures           : 15\n",
      "games                     : 10\n",
      "bitmasks                  : 7\n",
      "graphs                    : 4\n",
      "combinatorics             : 3\n",
      "shortest paths            : 2\n",
      "trees                     : 2\n",
      "dfs and similar           : 2\n",
      "geometry                  : 2\n",
      "dsu                       : 1\n",
      "matrices                  : 1\n",
      "ternary search            : 1\n",
      "\n",
      "User: mohd_fariq Rating: 1163 Predicted cluster: C0\n",
      "\n",
      "Topics weak -> strong:\n",
      "                  topic topic_state  accuracy  attempts\n",
      "                 graphs      STRONG  0.800000         5\n",
      "               sortings      STRONG  0.823529        51\n",
      "        data structures      STRONG  0.833333        18\n",
      "            brute force      STRONG  0.835821        67\n",
      "          binary search      STRONG  0.846154        26\n",
      "                 greedy      STRONG  0.881250       160\n",
      "                     dp      STRONG  0.884615        26\n",
      "constructive algorithms      STRONG  0.885246        61\n",
      "                   math      STRONG  0.893805       113\n",
      "                strings      STRONG  0.900000        30\n",
      "         implementation      STRONG  0.910891       101\n",
      "                  trees      MEDIUM  1.000000         2\n",
      "               geometry      MEDIUM  1.000000         2\n",
      "                  other      MEDIUM  1.000000         3\n",
      "          number theory      STRONG  1.000000        16\n",
      "\n",
      "Weakest topic: graphs\n",
      " contest_id problem_index                  problem_name  problem_rating  success_rate  solve_users  attempt_users                                       cf_link\n",
      "       1894             C           Anonymous Informant          1400.0           1.0           35             35 https://codeforces.com/contest/1894/problem/C\n",
      "        948             A                 Protect Sheep           900.0           1.0           33             33  https://codeforces.com/contest/948/problem/A\n",
      "         94             B                       Friends          1300.0           1.0           22             22   https://codeforces.com/contest/94/problem/B\n",
      "        802             J Send the Fool Further! (easy)          1400.0           1.0           19             19  https://codeforces.com/contest/802/problem/J\n",
      "        475             B       Strongly Connected City          1400.0           1.0           17             17  https://codeforces.com/contest/475/problem/B\n"
     ]
    }
   ],
   "source": [
    "new_user_report(\"mohd_fariq\", top_n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
